{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weightedsampler",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3445cedb07444e8a3e8df264996ca1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bb8cb34f627417ab3653024d407da2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44183e8ae7314651a0b292c4f358145b",
              "IPY_MODEL_ec2ca6dcb0c141af804dcb23a9de8959"
            ]
          }
        },
        "3bb8cb34f627417ab3653024d407da2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44183e8ae7314651a0b292c4f358145b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_654deea533a5446f959286fdeb9c5285",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80ab3a9e7a37487fb7cfbdd4164829bf"
          }
        },
        "ec2ca6dcb0c141af804dcb23a9de8959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b378765db265430da9afb90707d8e179",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25001/25001 [3:54:04&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d258eb36a70b48d0ade28052ae5d5742"
          }
        },
        "654deea533a5446f959286fdeb9c5285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80ab3a9e7a37487fb7cfbdd4164829bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b378765db265430da9afb90707d8e179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d258eb36a70b48d0ade28052ae5d5742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yim2VcRwuZim",
        "outputId": "0a65644f-cfc8-4a65-fcff-7a0ad77e0a3b"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/kaggle/input/lyft-motion-prediction-autonomous-vehicles'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import zipfile\n",
        "    !pip install -q kaggle\n",
        "    \n",
        "    from google.colab import files\n",
        "    if not os.path.exists('kaggle.json'):\n",
        "        files.upload()\n",
        "        !mkdir ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "    #!kaggle datasets list\n",
        "    !kaggle config path -p /content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def kaggle_dataset_download_unzip(lfilename,dir):\n",
        "\n",
        "        with zipfile.ZipFile(lfilename) as file: \n",
        "            file.extractall(dir)\n",
        "        os.remove(lfilename)\n",
        "\n",
        "    dir='/content/lyft-motion'\n",
        "    if not os.path.exists(dir):\n",
        "        !kaggle datasets download -d aikhmelnytskyy/liftfirst\n",
        "        lfilename='/content/liftfirst.zip'\n",
        "        kaggle_dataset_download_unzip(lfilename,dir+'/scenes')\n",
        "\n",
        "        !kaggle datasets download -d aikhmelnytskyy/lyftsecond\n",
        "        lfilename='/content/lyftsecond.zip'\n",
        "        kaggle_dataset_download_unzip(lfilename,dir)\n",
        "\n",
        "        !kaggle datasets download -d huanvo/lyft-pretrained-model-hv\n",
        "        lfilename='/content/lyft-pretrained-model-hv.zip'\n",
        "        kaggle_dataset_download_unzip(lfilename,'/content/lyft-pretrained-model-hv')\n",
        "        \n",
        "        data_path='/content/lyft-motion/'\n",
        "        weight_path='/content/lyft-pretrained-model-hv/model_multi_update_lyft_public.pth'\n",
        "        model_path='/content/drive/My Drive/Models/'#!!!!!!!!!!\n",
        "else:\n",
        "    data_path='/kaggle/input/lyft-motion-prediction-autonomous-vehicles'\n",
        "    weight_path='/kaggle/input/lyft-pretrained-model-hv/model_multi_update_lyft_public.pth' \n",
        "    model_path='' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "usage: kaggle config [-h] {view,set,unset} ...\n",
            "kaggle config: error: argument command: invalid choice: 'path' (choose from 'view', 'set', 'unset')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0aaQn1HucPj"
      },
      "source": [
        "# this script transports l5kit and dependencies\n",
        "!pip -q install pymap3d==2.1.0 \n",
        "!pip -q install protobuf==3.12.2 \n",
        "!pip -q install transforms3d \n",
        "!pip -q install zarr \n",
        "!pip -q install ptable\n",
        "\n",
        "!pip -q install --no-dependencies l5kit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37hJmHBpuw5s",
        "outputId": "929ca4a6-7878-441d-be1e-cbdf641605e5"
      },
      "source": [
        "import l5kit\n",
        "print(l5kit.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQezVEFTuzO4"
      },
      "source": [
        "# import packages\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc, os\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.resnet import resnet18, resnet34, resnet50\n",
        "from torchvision.models.densenet import densenet121\n",
        "from tqdm import tqdm\n",
        "from typing import Dict\n",
        "\n",
        "from l5kit.data import LocalDataManager, ChunkedDataset\n",
        "from l5kit.dataset import AgentDataset, EgoDataset\n",
        "from l5kit.rasterization import build_rasterizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc7QrjFqu0Xl"
      },
      "source": [
        "from typing import Dict\n",
        "\n",
        "from tempfile import gettempdir\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "# from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
        "from tqdm import tqdm\n",
        "\n",
        "import l5kit\n",
        "from l5kit.configs import load_config_data\n",
        "from l5kit.data import LocalDataManager, ChunkedDataset\n",
        "from l5kit.dataset import AgentDataset, EgoDataset\n",
        "from l5kit.rasterization import build_rasterizer\n",
        "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
        "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
        "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
        "from l5kit.geometry import transform_points\n",
        "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
        "from prettytable import PrettyTable\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm_notebook\n",
        "import gc, psutil\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQWJyt9bu3Jo",
        "outputId": "2d612859-02c2-44c5-c9af-2fb53667fae3"
      },
      "source": [
        "# Memory measurement\n",
        "def memory(verbose=True):\n",
        "    mem = psutil.virtual_memory()\n",
        "    gb = 1024*1024*1024\n",
        "    if verbose:\n",
        "        print('Physical memory:',\n",
        "              '%.2f GB (used),'%((mem.total - mem.available) / gb),\n",
        "              '%.2f GB (available)'%((mem.available) / gb), '/',\n",
        "              '%.2f GB'%(mem.total / gb))\n",
        "    return (mem.total - mem.available) / gb\n",
        "\n",
        "def gc_memory(verbose=True):\n",
        "    m = gc.collect()\n",
        "    if verbose:\n",
        "        print('GC:', m, end=' | ')\n",
        "        memory()\n",
        "\n",
        "memory();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Physical memory: 0.95 GB (used), 11.77 GB (available) / 12.72 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTunA0ATu4S6"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cldINbBeu6AI"
      },
      "source": [
        "# --- Lyft configs ---\n",
        "cfg = {\n",
        "    'format_version': 4,\n",
        "    'data_path': '/content/lyft-motion',\n",
        "    'model_params': {\n",
        "        'model_architecture': 'resnet34',\n",
        "        'history_num_frames': 10,\n",
        "        'history_step_size': 1,\n",
        "        'history_delta_time': 0.1,\n",
        "        'future_num_frames': 50,\n",
        "        'future_step_size': 1,\n",
        "        'future_delta_time': 0.1,\n",
        "        'model_name': \"model_resnet34_wegihted\",\n",
        "        'lr': 8e-6,\n",
        "        'weight_path': '/content/drive/MyDrive/weighted/model_resnet34_wegihted_weightsampler_output_180000.pth',\n",
        "        'train': True,\n",
        "        'predict': False,\n",
        "    },\n",
        "    'raster_params': {\n",
        "        'raster_size': [224, 224],\n",
        "        'pixel_size': [0.5, 0.5],\n",
        "        'ego_center': [0.25, 0.5],\n",
        "        'map_type': 'py_semantic',\n",
        "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
        "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
        "        'dataset_meta_key': 'meta.json',\n",
        "        'filter_agents_threshold': 0.5,\n",
        "    },\n",
        "    'train_data_loader': {\n",
        "        'key': 'scenes/train.zarr',\n",
        "        'batch_size': 8,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 1,\n",
        "    },    \n",
        "    'test_data_loader': {\n",
        "        'key': 'scenes/test.zarr',\n",
        "        'batch_size': 128,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 4,\n",
        "    },\n",
        "    'train_params': {\n",
        "        # 'steps': 100,\n",
        "        # 'update_steps': 10,\n",
        "        # 'checkpoint_steps': 50,\n",
        "        'steps': 25000,\n",
        "        'update_steps': 300,\n",
        "        'checkpoint_steps': 10000,\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_DROJ85u7F9"
      },
      "source": [
        "# set env variable for data\n",
        "DIR_INPUT = cfg[\"data_path\"]\n",
        "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
        "dm = LocalDataManager()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEgmeEPqu8UR"
      },
      "source": [
        "# --- Function utils ---\n",
        "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "def pytorch_neg_multi_log_likelihood_batch(\n",
        "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "    Compute a negative log-likelihood for the multi-modal scenario.\n",
        "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
        "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
        "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
        "    https://leimao.github.io/blog/LogSumExp/\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
        "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
        "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
        "\n",
        "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
        "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
        "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
        "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
        "    # assert all data are valid\n",
        "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
        "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
        "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
        "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
        "\n",
        "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
        "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
        "    avails = avails[:, None, :, None]  # add modes and cords\n",
        "\n",
        "    # error (batch_size, num_modes, future_len)\n",
        "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
        "\n",
        "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
        "        # error (batch_size, num_modes)\n",
        "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
        "\n",
        "    # use max aggregator on modes for numerical stability\n",
        "    # error (batch_size, num_modes)\n",
        "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
        "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
        "    # print(\"error\", error)\n",
        "    return torch.mean(error)\n",
        "\n",
        "\n",
        "def pytorch_neg_multi_log_likelihood_single(\n",
        "    gt: Tensor, pred: Tensor, avails: Tensor\n",
        ") -> Tensor:\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
        "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
        "    Returns:\n",
        "        Tensor: negative log-likelihood for this example, a single float number\n",
        "    \"\"\"\n",
        "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
        "    # create confidence (bs)x(mode=1)\n",
        "    batch_size, future_len, num_coords = pred.shape\n",
        "    confidences = pred.new_ones((batch_size, 1))\n",
        "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dyr_4Bi0onQ"
      },
      "source": [
        "class LyftMultiModel(nn.Module):\n",
        "    def __init__(self, cfg: Dict, num_modes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
        "        backbone = eval(architecture)(pretrained=True, progress=True)\n",
        "        self.backbone = backbone\n",
        "\n",
        "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
        "        num_in_channels = 3 + num_history_channels\n",
        "\n",
        "        self.backbone.conv1 = nn.Conv2d(\n",
        "            num_in_channels,\n",
        "            self.backbone.conv1.out_channels,\n",
        "            kernel_size=self.backbone.conv1.kernel_size,\n",
        "            stride=self.backbone.conv1.stride,\n",
        "            padding=self.backbone.conv1.padding,\n",
        "            bias=False,\n",
        "        )\n",
        "\n",
        "        # This is 512 for resnet18 and resnet34\n",
        "        # And it is 2048 for the other resnets        \n",
        "        if architecture == \"resnet50\":\n",
        "            backbone_out_features = 2048\n",
        "        else:\n",
        "            backbone_out_features = 512\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
        "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
        "        num_targets = 2 * self.future_len\n",
        "\n",
        "        # You can add more layers here.\n",
        "        self.head = nn.Sequential(\n",
        "            # nn.Dropout(0.2),\n",
        "            nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
        "        )\n",
        "\n",
        "        self.num_preds = num_targets * num_modes\n",
        "        self.num_modes = num_modes\n",
        "\n",
        "        self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        x = self.backbone.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.head(x)\n",
        "        x = self.logit(x)\n",
        "\n",
        "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
        "        # confidences (batch_size)x(modes)\n",
        "        bs, _ = x.shape\n",
        "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
        "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
        "        assert confidences.shape == (bs, self.num_modes)\n",
        "        confidences = torch.softmax(confidences, dim=1)\n",
        "        return pred, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFTTslNZu9ni"
      },
      "source": [
        "def forward(data, model, device, criterion=pytorch_neg_multi_log_likelihood_batch, compute_loss=True):\n",
        "    inputs = data[\"image\"].to(device)\n",
        "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
        "    targets = data[\"target_positions\"].to(device)\n",
        "    # Forward pass\n",
        "    preds, confidences = model(inputs)\n",
        "    # skip compute loss if we are doing prediction\n",
        "    loss = criterion(targets, preds, confidences, target_availabilities) if compute_loss else 0\n",
        "    return loss, preds, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxP8_xzbxVNx",
        "outputId": "ad43c68f-820b-42c7-8044-cfb057d0ac84"
      },
      "source": [
        "%%time\n",
        "# Build rasterizer\n",
        "rasterizer = build_rasterizer(cfg, dm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.98 s, sys: 157 ms, total: 4.14 s\n",
            "Wall time: 4.04 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbkhvE9YxXqp",
        "outputId": "b9beaf4e-5af9-457e-9c9f-dae325b439b6"
      },
      "source": [
        "%%time\n",
        "# Train dataset\n",
        "train_cfg = cfg[\"train_data_loader\"]\n",
        "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open(cached=False)  # to prevent run out of memory\n",
        "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], \n",
        "                              batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"])\n",
        "print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "CPU times: user 5.21 s, sys: 648 ms, total: 5.86 s\n",
            "Wall time: 5.75 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEm8l4GrxYvk"
      },
      "source": [
        "# %%time\n",
        "# if cfg[\"model_params\"][\"train\"]:\n",
        "#     # Train dataset\n",
        "#     train_cfg = cfg[\"train_data_loader\"]\n",
        "#     train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open(cached=False)  # to prevent run out of memory\n",
        "#     train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "    \n",
        "#     # samples_weight = torch.from_numpy(samples_weight)\n",
        "#     # sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))   \n",
        "#     # train_dataloader = DataLoader(train_dataset, shuffle=False, \n",
        "#     #                               batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"],sampler=sampler)\n",
        "\n",
        "#     train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], \n",
        "#                                   batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"])\n",
        "#     print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-0h0MmjxbOq",
        "outputId": "7f3580f5-bab4-4aac-f1f0-7437601b0cfe"
      },
      "source": [
        "len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2812089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqIrJxRdxeu-",
        "outputId": "449ebbe2-cfda-49e8-e043-8200d1a44eaa"
      },
      "source": [
        "%%time\n",
        "if cfg[\"model_params\"][\"train\"]:\n",
        "    # Train dataset\n",
        "    train_cfg = cfg[\"train_data_loader\"]\n",
        "    train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open(cached=False)  # to prevent run out of memory\n",
        "    train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "    \n",
        "    # #######################################################\n",
        "    # start testing weight sampler;\n",
        "    from sklearn import datasets, linear_model\n",
        "    from sklearn.metrics import mean_squared_error, r2_score\n",
        "    from torch.utils.data.sampler import Sampler\n",
        "    from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "    # define label series;\n",
        "    total_length = cfg[\"train_data_loader\"][\"batch_size\"]*cfg[\"train_params\"][\"steps\"]\n",
        "    \n",
        "    y_train = np.zeros(total_length)\n",
        "    \n",
        "    for idx in range(total_length):\n",
        "        data = train_dataset[idx]\n",
        "        \n",
        "        x = data['target_positions'][:,0]\n",
        "        y = data['target_positions'][:,1]\n",
        "        x = x.reshape((50,1))\n",
        "        \n",
        "        # linear regression, calculate r2\n",
        "        regr = linear_model.LinearRegression()\n",
        "        regr.fit(x, y)\n",
        "        y_pred = regr.predict(x)\n",
        "    \n",
        "        r2 = r2_score(y, y_pred)\n",
        "        \n",
        "        # use r2 to create label;\n",
        "        if r2<=0.4:\n",
        "            y_train[idx] = 0\n",
        "        else:\n",
        "            if r2>=0.6:\n",
        "                y_train[idx] = 2\n",
        "            else:\n",
        "                y_train[idx] = 1\n",
        "    \n",
        "    # After y_train is created, create weight sampler;\n",
        "    y_train = y_train.astype(int)  # label has to be interger;\n",
        "    class_sample_count = np.array([len(np.where(y_train==t)[0]) for t in np.unique(y_train)])\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in y_train])\n",
        "\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
        "    # #######################################################\n",
        "    \n",
        "    train_dataloader = DataLoader(train_dataset, shuffle=False, \n",
        "                                  batch_size=train_cfg[\"batch_size\"], num_workers=train_cfg[\"num_workers\"],sampler=sampler)\n",
        "    print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
            "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
            "CPU times: user 3h 24min 54s, sys: 2h 40min 58s, total: 6h 5min 52s\n",
            "Wall time: 3h 6min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5FlSMfc0i91",
        "outputId": "c4095566-e88f-41f2-f2ba-b0dbf6eb0ceb"
      },
      "source": [
        "%%time\n",
        "# ==== INIT MODEL=================\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LyftMultiModel(cfg)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=cfg[\"model_params\"][\"lr\"])\n",
        "\n",
        "#load weight if there is a pretrained model\n",
        "# epoch = 1\n",
        "# WEIGHT_FILE = cfg[\"model_params\"][\"weight_path\"]\n",
        "# checkpoint = torch.load(WEIGHT_FILE, map_location=device)\n",
        "# model.load_state_dict(checkpoint)\n",
        "\n",
        "WEIGHT_FILE = cfg[\"model_params\"][\"weight_path\"]\n",
        "checkpoint = torch.load(WEIGHT_FILE, map_location=device)\n",
        "epoch = checkpoint['epoch']\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "print(f'device {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device cuda:0\n",
            "CPU times: user 752 ms, sys: 530 ms, total: 1.28 s\n",
            "Wall time: 1.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky6MtK4O0vGE",
        "outputId": "89f79a54-688f-409a-e5ce-162bfb462791"
      },
      "source": [
        "epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d3445cedb07444e8a3e8df264996ca1e",
            "3bb8cb34f627417ab3653024d407da2f",
            "44183e8ae7314651a0b292c4f358145b",
            "ec2ca6dcb0c141af804dcb23a9de8959",
            "654deea533a5446f959286fdeb9c5285",
            "80ab3a9e7a37487fb7cfbdd4164829bf",
            "b378765db265430da9afb90707d8e179",
            "d258eb36a70b48d0ade28052ae5d5742"
          ]
        },
        "id": "mBFVsjjTzUBi",
        "outputId": "7fe083eb-854a-4add-da02-a82be0d517cb"
      },
      "source": [
        "%%time\n",
        "if cfg[\"model_params\"][\"train\"]:\n",
        "    tr_it = iter(train_dataloader)\n",
        "    n_steps = cfg[\"train_params\"][\"steps\"]\n",
        "    progress_bar = tqdm_notebook(range(epoch, 1 + epoch + cfg[\"train_params\"][\"steps\"]), mininterval=10.)\n",
        "    losses = []\n",
        "    iterations = []\n",
        "    metrics = []\n",
        "    memorys = []\n",
        "    times = []\n",
        "    model_name = cfg[\"model_params\"][\"model_name\"]\n",
        "    update_steps = cfg['train_params']['update_steps']\n",
        "    checkpoint_steps = cfg['train_params']['checkpoint_steps']\n",
        "    t_start = time.time()\n",
        "    torch.set_grad_enabled(True)\n",
        "        \n",
        "    for i in progress_bar:\n",
        "        try:\n",
        "            data = next(tr_it)\n",
        "        except StopIteration:\n",
        "            tr_it = iter(train_dataloader)\n",
        "            data = next(tr_it)\n",
        "        model.train()   # somehow we need this is ever batch or it perform very bad (not sure why)\n",
        "        loss, _, _ = forward(data, model, device)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_v = loss.item()\n",
        "        losses.append(loss_v)\n",
        "        \n",
        "        if i % update_steps == 0:\n",
        "            mean_losses = np.mean(losses)\n",
        "            timespent = (time.time() - t_start) / 60\n",
        "            print('i: %5d'%i,\n",
        "                  'loss: %10.5f'%loss_v, 'loss(avg): %10.5f'%mean_losses, \n",
        "                  '%.2fmins'%timespent, end=' | ')\n",
        "            mem = memory()\n",
        "            # if i % checkpoint_steps == 0:\n",
        "            #     torch.save(model.state_dict(), f'{model_name}_{i}.pth')\n",
        "            #     torch.save(optimizer.state_dict(), f'{model_name}_optimizer_{i}.pth')\n",
        "            if i % checkpoint_steps == 0:\n",
        "                torch.save({'epoch': i,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                            'optimizer_state_dict': optimizer.state_dict()},\n",
        "                           f'/content/drive/MyDrive/weighted/{model_name}_weightsampler_output_{i}.pth') \n",
        "            iterations.append(i)\n",
        "            metrics.append(mean_losses)\n",
        "            memorys.append(mem)\n",
        "            times.append(timespent)\n",
        "    \n",
        "    results = pd.DataFrame({\n",
        "        'iterations': iterations, \n",
        "        'metrics (avg)': metrics,\n",
        "        'elapsed_time (mins)': times,\n",
        "        'memory (GB)': memorys,\n",
        "    })\n",
        "    results.to_csv(f'/content/drive/MyDrive/weighted/train_metrics_weightsampler_{model_name}_{i}.csv', index=False)\n",
        "    print(f'Total training time is {(time.time() - t_start) / 60} mins')\n",
        "    memory()\n",
        "    display(results)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3445cedb07444e8a3e8df264996ca1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25001.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "i: 180000 loss:    3.38257 loss(avg):    3.38257 0.01mins | Physical memory: 5.80 GB (used), 6.92 GB (available) / 12.72 GB\n",
            "i: 180300 loss:    3.86095 loss(avg):    9.09013 2.90mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 180600 loss:   10.49522 loss(avg):    8.15398 5.72mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 180900 loss:   10.76817 loss(avg):    7.86792 8.55mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 181200 loss:   14.22308 loss(avg):    7.76226 11.34mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 181500 loss:    4.43025 loss(avg):    7.78608 14.14mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 181800 loss:    5.26085 loss(avg):    7.81275 16.98mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 182100 loss:    1.34625 loss(avg):    7.77708 19.82mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 182400 loss:    2.38436 loss(avg):    7.74909 22.66mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 182700 loss:    1.75973 loss(avg):    7.76174 25.48mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 183000 loss:    7.13566 loss(avg):    7.71311 28.27mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 183300 loss:    2.96980 loss(avg):    7.63065 31.06mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 183600 loss:    4.65817 loss(avg):    7.54605 33.88mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 183900 loss:    5.46903 loss(avg):    7.48871 36.69mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 184200 loss:    6.85823 loss(avg):    7.46809 39.47mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 184500 loss:   13.82132 loss(avg):    7.54491 42.26mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 184800 loss:    5.73449 loss(avg):    7.50685 45.06mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 185100 loss:    6.06423 loss(avg):    7.45005 47.88mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 185400 loss:    6.20705 loss(avg):    7.43374 50.67mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 185700 loss:    3.41528 loss(avg):    7.43430 53.46mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 186000 loss:    3.56668 loss(avg):    7.43529 56.26mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 186300 loss:   13.21989 loss(avg):    7.42599 59.07mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 186600 loss:    5.18853 loss(avg):    7.42006 61.89mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 186900 loss:    3.46976 loss(avg):    7.38765 64.71mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 187200 loss:    3.86746 loss(avg):    7.38375 67.51mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 187500 loss:    5.33926 loss(avg):    7.38961 70.30mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 187800 loss:    2.11454 loss(avg):    7.37912 73.11mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 188100 loss:    5.01714 loss(avg):    7.32349 75.92mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 188400 loss:    5.50970 loss(avg):    7.29730 78.72mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 188700 loss:    3.42409 loss(avg):    7.28780 81.53mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 189000 loss:    6.04441 loss(avg):    7.27573 84.34mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 189300 loss:   10.97012 loss(avg):    7.32899 87.14mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 189600 loss:    2.26431 loss(avg):    7.30552 89.95mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 189900 loss:    2.06366 loss(avg):    7.29186 92.75mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 190200 loss:    5.63709 loss(avg):    7.28297 95.53mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 190500 loss:    6.33686 loss(avg):    7.26753 98.35mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 190800 loss:    4.67688 loss(avg):    7.28201 101.16mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 191100 loss:    2.99135 loss(avg):    7.24466 103.97mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 191400 loss:    2.57777 loss(avg):    7.23175 106.80mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 191700 loss:    4.74857 loss(avg):    7.24236 109.61mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 192000 loss:    4.52232 loss(avg):    7.22477 112.41mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 192300 loss:    8.22796 loss(avg):    7.19502 115.21mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 192600 loss:    3.76354 loss(avg):    7.18207 117.98mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 192900 loss:    8.77254 loss(avg):    7.18061 120.78mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 193200 loss:    4.60090 loss(avg):    7.16906 123.58mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 193500 loss:    6.50813 loss(avg):    7.16499 126.41mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 193800 loss:   11.87561 loss(avg):    7.15757 129.23mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 194100 loss:    3.38493 loss(avg):    7.16542 132.01mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 194400 loss:   11.57684 loss(avg):    7.14352 134.82mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 194700 loss:    3.92050 loss(avg):    7.12382 137.61mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 195000 loss:    3.64110 loss(avg):    7.09856 140.40mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 195300 loss:    7.12040 loss(avg):    7.08971 143.19mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 195600 loss:    6.80976 loss(avg):    7.07487 146.00mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 195900 loss:    1.55368 loss(avg):    7.09185 148.79mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 196200 loss:    1.77411 loss(avg):    7.14565 151.61mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 196500 loss:    7.45379 loss(avg):    7.13108 154.40mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 196800 loss:    3.60847 loss(avg):    7.12356 157.21mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 197100 loss:    2.12019 loss(avg):    7.10890 159.99mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 197400 loss:    5.38120 loss(avg):    7.09565 162.78mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 197700 loss:   17.81145 loss(avg):    7.08798 165.57mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 198000 loss:    7.48167 loss(avg):    7.08761 168.39mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 198300 loss:    5.69737 loss(avg):    7.08563 171.20mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 198600 loss:    5.65521 loss(avg):    7.06704 174.01mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 198900 loss:    2.46480 loss(avg):    7.05939 176.82mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 199200 loss:    2.46033 loss(avg):    7.05338 179.65mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 199500 loss:    9.29601 loss(avg):    7.04338 182.46mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 199800 loss:    4.91658 loss(avg):    7.03932 185.27mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 200100 loss:    3.66168 loss(avg):    7.01552 188.10mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 200400 loss:    2.14886 loss(avg):    7.00563 190.93mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 200700 loss:    3.56073 loss(avg):    6.98955 193.73mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 201000 loss:    4.51296 loss(avg):    6.98023 196.55mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 201300 loss:    4.22375 loss(avg):    6.96942 199.37mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 201600 loss:    4.70629 loss(avg):    6.96798 202.18mins | Physical memory: 5.81 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 201900 loss:    1.02825 loss(avg):    6.96602 205.00mins | Physical memory: 5.83 GB (used), 6.89 GB (available) / 12.72 GB\n",
            "i: 202200 loss:    6.75345 loss(avg):    6.96454 207.83mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 202500 loss:    3.19833 loss(avg):    6.95080 210.64mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 202800 loss:    6.02654 loss(avg):    6.92995 213.44mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 203100 loss:   13.11088 loss(avg):    6.91826 216.27mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 203400 loss:    5.76088 loss(avg):    6.90792 219.08mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 203700 loss:    5.49584 loss(avg):    6.90573 221.89mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 204000 loss:   13.13836 loss(avg):    6.89263 224.70mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 204300 loss:    5.09345 loss(avg):    6.87938 227.50mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 204600 loss:    5.55459 loss(avg):    6.86427 230.31mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "i: 204900 loss:    8.89551 loss(avg):    6.85326 233.13mins | Physical memory: 5.82 GB (used), 6.90 GB (available) / 12.72 GB\n",
            "\n",
            "Total training time is 234.07804174423217 mins\n",
            "Physical memory: 5.80 GB (used), 6.92 GB (available) / 12.72 GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iterations</th>\n",
              "      <th>metrics (avg)</th>\n",
              "      <th>elapsed_time (mins)</th>\n",
              "      <th>memory (GB)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>180000</td>\n",
              "      <td>3.382572</td>\n",
              "      <td>0.010615</td>\n",
              "      <td>5.795967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>180300</td>\n",
              "      <td>9.090127</td>\n",
              "      <td>2.901284</td>\n",
              "      <td>5.815388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180600</td>\n",
              "      <td>8.153977</td>\n",
              "      <td>5.724428</td>\n",
              "      <td>5.813694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>180900</td>\n",
              "      <td>7.867917</td>\n",
              "      <td>8.552334</td>\n",
              "      <td>5.814510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>181200</td>\n",
              "      <td>7.762260</td>\n",
              "      <td>11.344779</td>\n",
              "      <td>5.815762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>203700</td>\n",
              "      <td>6.905733</td>\n",
              "      <td>221.893839</td>\n",
              "      <td>5.817616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>204000</td>\n",
              "      <td>6.892628</td>\n",
              "      <td>224.698605</td>\n",
              "      <td>5.818489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>204300</td>\n",
              "      <td>6.879376</td>\n",
              "      <td>227.496606</td>\n",
              "      <td>5.818222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>204600</td>\n",
              "      <td>6.864270</td>\n",
              "      <td>230.313659</td>\n",
              "      <td>5.818901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>204900</td>\n",
              "      <td>6.853257</td>\n",
              "      <td>233.131411</td>\n",
              "      <td>5.819748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    iterations  metrics (avg)  elapsed_time (mins)  memory (GB)\n",
              "0       180000       3.382572             0.010615     5.795967\n",
              "1       180300       9.090127             2.901284     5.815388\n",
              "2       180600       8.153977             5.724428     5.813694\n",
              "3       180900       7.867917             8.552334     5.814510\n",
              "4       181200       7.762260            11.344779     5.815762\n",
              "..         ...            ...                  ...          ...\n",
              "79      203700       6.905733           221.893839     5.817616\n",
              "80      204000       6.892628           224.698605     5.818489\n",
              "81      204300       6.879376           227.496606     5.818222\n",
              "82      204600       6.864270           230.313659     5.818901\n",
              "83      204900       6.853257           233.131411     5.819748\n",
              "\n",
              "[84 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30min 25s, sys: 4min 58s, total: 35min 23s\n",
            "Wall time: 3h 54min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNzjgGKQzYpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "eba9045f-2e52-4dda-eb48-8b148b8debc7"
      },
      "source": [
        "if cfg[\"model_params\"][\"train\"]:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(results['iterations'], results['metrics (avg)'])\n",
        "    plt.xlabel('steps'); plt.ylabel('metrics (avg)')\n",
        "    plt.grid(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(results['iterations'], results['memory (GB)'])\n",
        "    plt.xlabel('steps'); plt.ylabel('memory (GB)')\n",
        "    plt.grid(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(results['iterations'], results['elapsed_time (mins)'])\n",
        "    plt.xlabel('steps'); plt.ylabel('elapsed_time (mins)')\n",
        "    plt.grid(); plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc91a270ba80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics (avg)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrics (avg)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmFzEQQifMFL"
      },
      "source": [
        " torch.save({'epoch': i,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                            'optimizer_state_dict': optimizer.state_dict()},\n",
        "                           f'/content/drive/MyDrive/weighted/{model_name}_weightsampler_output_{i}.pth') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap1ifS3dWhfj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}